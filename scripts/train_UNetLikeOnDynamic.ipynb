{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train my [UNetLike](http://eg.bucknell.edu/~jvs008/research/cardiac/SPIE20/SPIE20.html) model on the [Stanford data](https://echonet.github.io/dynamic/)\n",
    "Stough, 6/20\n",
    "\n",
    "Pretty self-explanatory\n",
    "\n",
    "The 2D echonet model (really, deeplabv3) applied to the CAMUS data yielded in the low 80s Dice (see [play_DynamicSegmentsCAMUS.ipynb](play_DynamicSegmentsCAMUS.ipynb)). My UNetLike model trained on CAMUS, applied to the echonet dataset yielded in the high 80s (see [play_camusSegmentsDynamic.ipynb](play_camusSegmentsDynamic.ipynb)). \n",
    "\n",
    "So the next question: What if we **trained** my model on the echonet dataset? \n",
    "\n",
    "Since echonet provides a useful Dataset type already, I use the DataLoader from echonet, and only after do my additional camusizing transforms (single channel, 256x256, 0-1 intensities) and potentially data augmentations (rotation, windowing, noise through the callable objects such as random_GaussNoiser in camus.utils.camus_transforms), this will definitely create a bottleneck in training since I don't want to try to multiprocess it right now...\n",
    "\n",
    "Since my UNetLike training on CAMUS was specific to that project, I have to rewrite run_training and run_validation...I'll just write them in this bloated notebook for prototyping...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import SimpleITK as itk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import tempfile\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Being able to use the utility functions here.\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('camus'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "    \n",
    "sys.path.insert(0, 'camus/utils/')\n",
    "\n",
    "\n",
    "from camus.utils.camus_config import CAMUS_CONFIG\n",
    "from camus.utils.echo_utils import makeVideo\n",
    "from camus.utils.camus_load_info import (make_camus_echo_dataset,\n",
    "                                       split_camus_echo,\n",
    "                                       make_camus_EHR,\n",
    "                                       CAMUS_TRAINING_DIR,\n",
    "                                       CAMUS_TESTING_DIR,\n",
    "                                       CAMUS_RESULTS_DIR)\n",
    "from camus.utils.camus_transforms import (LoadSITKFromFilename,\n",
    "                                        SitkToNumpy,\n",
    "                                        ResizeTransform,\n",
    "                                        ResizeImagesAndLabels,\n",
    "                                        WindowImagesAndLabels,\n",
    "                                        RotateImagesAndLabels,\n",
    "                                        random_Rotater,\n",
    "                                        random_GaussNoiser,\n",
    "                                        random_Windower,\n",
    "                                        identity_Transform,\n",
    "                                        GaussianNoiseEcho)\n",
    "from camus.utils.camus_validate import (camus_overlay,\n",
    "                                      labColorMap,\n",
    "                                      labColor_cmap,\n",
    "                                      labNameMap,\n",
    "                                      nameLabMap,\n",
    "                                      dict_extend_values,\n",
    "                                      camus_dice_by_name,\n",
    "                                      cleanupBinary,\n",
    "                                      cleanupSegmentation)\n",
    "from camus.utils.torch_utils import (TransformDataset,\n",
    "                                   torch_collate,\n",
    "                                   BetterLoss)\n",
    "from camus.torch_models import UNetLike\n",
    "from camus.segment_common import segment_echo\n",
    "\n",
    "from camus.utils.echo_utils import (transformResizeImage,\n",
    "                                    readTransformResizeImage)\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "from scipy.special import softmax\n",
    "\n",
    "from skimage.transform import (rescale, \n",
    "                               resize, \n",
    "                               rotate)\n",
    "\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch.utils.data import (DataLoader, Dataset)\n",
    "from torchvision.transforms import Compose\n",
    "from torch.nn.functional import interpolate\n",
    "\n",
    "# For timing.\n",
    "import time\n",
    "tic, toc = (time.time, time.time)\n",
    "\n",
    "import echonet\n",
    "from argparse import Namespace\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Namespace(**CAMUS_CONFIG['training']) # make a Namespace out of a dictionary.\n",
    "augment_args = Namespace(**CAMUS_CONFIG['augment'])\n",
    "unet_args = Namespace(**CAMUS_CONFIG['unet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 16,\n",
      " 'effective_batchsize': 1,\n",
      " 'howOftenToReport': 10,\n",
      " 'image_size': [256, 256],\n",
      " 'learning_rate': 0.001,\n",
      " 'loss_weights': [1, 1, 1, 1],\n",
      " 'num_epochs': 300,\n",
      " 'patienceLimit': 41,\n",
      " 'patienceToLRcut': 10,\n",
      " 'weight_decay': 1e-06}\n",
      "{'noise_scale': [0.0, 0.15],\n",
      " 'rotation_scale': 5.0,\n",
      " 'training_augment': True,\n",
      " 'windowing_scale': [0.5, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "# pretty print a namespace.  pprint doesn't work. vars of a namespace gives you back the dictionary...\n",
    "pprint(vars(training_args))\n",
    "\n",
    "pprint(vars(augment_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Set up the Echonet Datasets and DataLoaders.\n",
    "\n",
    "We'll also setup the processing post the Echonet dataloaders \n",
    "that actually fit the data into our network. We'll do this through \n",
    "a camusizer object (ripped from [play_camusSegmentsDynamic.ipynb](play_camusSegmentsDynamic.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 14.32it/s]\n"
     ]
    }
   ],
   "source": [
    "tasks = [\"LargeFrame\", \"SmallFrame\", \"LargeTrace\", \"SmallTrace\"]\n",
    "mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"train\"))\n",
    "kwargs = {\"target_type\": tasks,\n",
    "          \"mean\": mean,\n",
    "          \"std\": std\n",
    "         }\n",
    "\n",
    "\n",
    "param_trainLoader = {\n",
    "    'batch_size': training_args.batch_size//2, # both ED/ES come with each, so halve batch_size to the echonet loader.\n",
    "    'num_workers': 4,\n",
    "    'shuffle': True,\n",
    "    'pin_memory': False,\n",
    "    'drop_last': True}\n",
    "\n",
    "param_ValTestLoader = {\n",
    "    'batch_size': training_args.batch_size//2,\n",
    "    'num_workers': 4,\n",
    "    'shuffle': False,\n",
    "    'pin_memory': False,\n",
    "    'drop_last': False}\n",
    "\n",
    "paramLoader = {'train': param_trainLoader,\n",
    "               'val': param_ValTestLoader,\n",
    "               'test':  param_ValTestLoader}\n",
    "\n",
    "\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "\n",
    "for datatype in ['train', 'val', 'test']:\n",
    "    datasets[datatype] = echonet.datasets.Echo(split=datatype, **kwargs)\n",
    "    dataloaders[datatype] = torch.utils.data.DataLoader(datasets[datatype],\n",
    "                                                        **paramLoader[datatype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Camusize object takes the tuple that comes from a Echnet dataloader \n",
    "and reformats it to be appropriate to train the UNetLike model on:\n",
    "So, the echonet dataloader is iterated like:\n",
    "for (_, (large_frame, small_frame, large_trace, small_trace)) in test_dataloader:\n",
    "\n",
    "where [large,small]_[frame,trace] are N x [3,1] x 112 x 112 (3 for echo frame, \n",
    "1 for trace) tensors. The echo frames are further mean/var normalized. \n",
    "My UNetLike works on (N x):\n",
    "1 x 256 x 256 (single channel echo frames)\n",
    "[0,1] range\n",
    "\n",
    "So this class's object call is to cat to cat the [large,small] frames and traces\n",
    "and convert to appropriate for UNetLike. So it takes the dataloader sample above and \n",
    "returns the appropriately formatted two-tuple (frames, traces)\n",
    "'''\n",
    "class Camusize(object):\n",
    "    def __init__(self, im_size):\n",
    "        self.im_size = im_size\n",
    "        \n",
    "    def _norm(self, frames):\n",
    "        # make 0-1, but in tensors:\n",
    "        # https://discuss.pytorch.org/t/how-to-efficiently-normalize-a-batch-of-tensor-to-0-1/65122/4\n",
    "        AA = frames.clone()\n",
    "        AA = AA.view(frames.size(0), -1)\n",
    "        AA -= AA.min(1, keepdim=True)[0]\n",
    "        AA /= AA.max(1, keepdim=True)[0]\n",
    "        AA = AA.view(frames.shape)\n",
    "        return AA\n",
    "    \n",
    "    def _rgb2gray(self, frames):\n",
    "        # 0.2989 * R + 0.5870 * G + 0.1140 * B \n",
    "        # In torch tensors a bit tougher. I'll just do the mean...\n",
    "        # return np.multiply(frame, np.array([.2989, .5870, .1140])[:, None, None]).sum(axis=0)\n",
    "        return torch.mul(frames, torch.tensor([.2989, .5870, .1140])[None, :, None, None]).sum(1, keepdim=True)\n",
    "#         return frames.mean(1, keepdim=True)\n",
    "        \n",
    "    '''\n",
    "    Object call: Should take frame and trace batches and convert to\n",
    "    CAMUS-acceptable images (in [0-1], and 256x256 single channel):\n",
    "    frames is n x 3 x 112 x 112 tensor\n",
    "    traces is n x 112 x 112 tensor\n",
    "    '''\n",
    "    def __call__(self, echonet_tuple):\n",
    "        _, (large_frame, small_frame, large_trace, small_trace) = echonet_tuple\n",
    "        \n",
    "        frames = torch.cat((large_frame, small_frame), 0)\n",
    "        traces = torch.cat((large_trace, small_trace), 0)\n",
    "        \n",
    "        out_frames = self._norm(frames)\n",
    "        out_frames = self._rgb2gray(out_frames)\n",
    "        out_frames = interpolate(out_frames, size=self.im_size, \n",
    "                                 mode='bilinear', align_corners=False)\n",
    "        \n",
    "        out_traces = interpolate(traces.unsqueeze(1), size=self.im_size,\n",
    "                                 mode='nearest').squeeze().type(torch.long)\n",
    "        \n",
    "        return out_frames, out_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ripped from camus_overlay and camusSegmentsDynamic\n",
    "def overlay(im, lab, lab_gt=None, alpha = 1.0, whichLabels = [0,1]):\n",
    "\n",
    "    # Just a three channel version of the echo image.\n",
    "    # I = im.transpose([1,2,0]).copy()\n",
    "    I = np.stack([im,im,im], axis=-1)\n",
    "    \n",
    "    # Special image for lab_gt versus lab.\n",
    "    if lab_gt is not None:\n",
    "        if len(lab_gt.shape) == 3: # maybe, for some reason, 1 x h x w was provided...\n",
    "            lab_gt = lab_gt.squeeze()\n",
    "            \n",
    "        I_gt = I.copy()\n",
    "        \n",
    "        # Make complementary colors for the label/gt difference overlay.\n",
    "        gtCompColors = {}\n",
    "        for key, val in labColorMap.items():\n",
    "            mx = max(val)\n",
    "            gtCompColors[key] = [mx-x for x in val]\n",
    "\n",
    "    # Regular lab image of keys instead of network output. Expected h x w\n",
    "    # Now add the lab image to the echo.\n",
    "    mchanLabelKey = lab.copy() # assigning this so the lab_gt stuff still works below\n",
    "    for key in whichLabels:\n",
    "        I[lab==key,:] += alpha*np.array(labColorMap[key])\n",
    "      \n",
    "    \n",
    "    if lab_gt is not None:\n",
    "        for key in [1]: # hardcode, sorry. Want LV to show best.\n",
    "            whereFP = np.logical_and(mchanLabelKey == key, lab_gt != key)\n",
    "            whereFN = np.logical_and(mchanLabelKey != key, lab_gt == key)\n",
    "                \n",
    "                # Getting the shapes right is difficult.\n",
    "#                 I_gt[whereFP,:] += np.reshape([0, .2*key, 0], (1,3))\n",
    "#                 I_gt[whereFN,:] += np.reshape([.2*key, 0, 0], (1,3))\n",
    "            I_gt[whereFP,:] += labColorMap[key]\n",
    "            I_gt[whereFN,:] += gtCompColors[key] # false negative is color complement\n",
    "            \n",
    "        I_gt = I_gt.clip(0,1)\n",
    "\n",
    "    I = I.clip(0,1)\n",
    "    \n",
    "    if lab_gt is not None:\n",
    "        return I, I_gt\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15de4b7152dd4802aaac210de77364c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1215ea5a778445248116acfd43f36c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1bdab208844a7986e324ab5ab75f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71946d2d93e473596d8a5ad4de67f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adaa616e4bfa466d9f197248ef59dc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (frames, traces) in enumerate(map(Camusize(im_size=training_args.image_size), dataloaders['test'])):\n",
    "    if i >= 5:\n",
    "        break\n",
    "        \n",
    "    f, ax = plt.subplots(1,2, figsize=(4,2))\n",
    "    Io = overlay(frames[0].squeeze(), lab=traces[0].numpy())\n",
    "    ax[0].imshow(frames[0].squeeze(), cmap='gray', interpolation=None)\n",
    "    ax[1].imshow(Io, interpolation=None)\n",
    "    \n",
    "    [a.axes.get_xaxis().set_visible(False) for a in ax]\n",
    "    [a.axes.get_yaxis().set_visible(False) for a in ax]\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 256, 256]),\n",
       " torch.Size([16, 256, 256]),\n",
       " tensor(0.0002),\n",
       " tensor(0.9995))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape, traces.shape, frames.min(), frames.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Let's instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_channels': 1, 'n_classes': 2, 'n_filters': 32, 'normalization': 'groupnorm'}\n"
     ]
    }
   ],
   "source": [
    "unet_args.n_classes = 2\n",
    "pprint(vars(unet_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using the UNetLike 2d seg from torch_models.\n",
    "\n",
    "net_seg = UNetLike(**vars(unet_args))\n",
    "net_seg = torch.nn.DataParallel(net_seg)\n",
    "net_seg.cuda(); # semicolon suppresses summary printout of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 13068034\n",
      "Or maybe: 13068034\n"
     ]
    }
   ],
   "source": [
    "# Number of trainable parameters?\n",
    "# https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\n",
    "print('Trainable params: {}'.format(sum(p.numel() for p in net_seg.parameters() if p.requires_grad)))\n",
    "\n",
    "# Or\n",
    "# https://gist.github.com/zackenton/12a86b6e0ff274b39608e40f4a412f2b\n",
    "from functools import reduce\n",
    "def pytorch_count_params(model):\n",
    "    '''count number trainable parameters in a pytorch model'''\n",
    "    total_params = sum(reduce( lambda a, b: a*b, x.size()) for x in model.parameters())\n",
    "    return total_params\n",
    "\n",
    "print('Or maybe: {}'.format(pytorch_count_params(net_seg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Training and Validation Functions\n",
    "\n",
    "I'm ripping most of the content from camus/torch_utils, but I wrote those\n",
    "with my CAMUS dictionary-based dataloader in mind. I could wrap the Camusize \n",
    "class above in an iterable to yield something that could trick that other \n",
    "code, but it seems more straightforward to just write my own loops for this \n",
    "little experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(network,  \n",
    "                 effective_batchsize,\n",
    "                 criterion = BetterLoss(),\n",
    "                 cur_learning_rate=1e-3,\n",
    "                 cur_weight_decay=1e-5):\n",
    "    \n",
    "    \n",
    "    network.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(network.parameters(),\n",
    "                                 lr=cur_learning_rate,\n",
    "                                 weight_decay=cur_weight_decay)\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for batch_num, (inputs, correct_outputs) in enumerate(map(Camusize(im_size=training_args.image_size), dataloaders['train'])):\n",
    "        \n",
    "        if torch.cuda.is_available:\n",
    "            inputs, correct_outputs = inputs.cuda(), correct_outputs.cuda()\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, correct_outputs = Variable(inputs), Variable(correct_outputs)\n",
    "        \n",
    "        \n",
    "        # get network output\n",
    "        net_outputs = network(inputs)\n",
    "    \n",
    "        net_loss = criterion(net_outputs, correct_outputs)\n",
    "\n",
    "        net_loss.backward()\n",
    "        \n",
    "        if (i % effective_batchsize) == 0:\n",
    "            optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        running_loss += net_loss.detach().cpu().item()\n",
    "        \n",
    "    \n",
    "    # Only using the last for example output.\n",
    "    net_outputs = net_outputs.detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "    # Ready to return info, including loss and example.\n",
    "    avg_loss = running_loss / len(dataloaders['train'])\n",
    "    one_output = net_outputs[0]    \n",
    "    one_input = inputs.detach().cpu().numpy()[0]\n",
    "    one_correct_output = correct_outputs.detach().cpu().numpy()[0]\n",
    "    \n",
    "    return avg_loss, one_output, one_input, one_correct_output\n",
    "\n",
    "\n",
    "def run_validation(network,\n",
    "                   phase = 'val', # 'valid', 'test'\n",
    "                   criterion = BetterLoss()):\n",
    "    # Prevent weight updates.\n",
    "    network.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (inputs, correct_outputs) in enumerate(map(Camusize(im_size=training_args.image_size), dataloaders[phase])):\n",
    "\n",
    "            if torch.cuda.is_available:\n",
    "                inputs, correct_outputs = inputs.cuda(), correct_outputs.cuda()\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, correct_outputs = Variable(inputs), Variable(correct_outputs)\n",
    "\n",
    "\n",
    "            # get network output\n",
    "            net_outputs = network(inputs)\n",
    "\n",
    "            net_loss = criterion(net_outputs, correct_outputs)\n",
    "\n",
    "            running_loss += net_loss.detach().cpu().item()\n",
    "            \n",
    "        \n",
    "        # Only using the last for example output.\n",
    "        net_outputs = net_outputs.detach().cpu().numpy()\n",
    "            \n",
    "\n",
    "\n",
    "    # Ready to return info, including loss and example.\n",
    "    avg_loss = running_loss / len(dataloaders[phase])\n",
    "    one_output = net_outputs[0]    \n",
    "    one_input = inputs.detach().cpu().numpy()[0]\n",
    "    one_correct_output = correct_outputs.detach().cpu().numpy()[0]\n",
    "    \n",
    "    return avg_loss, one_output, one_input, one_correct_output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## The Actual Experimental Loop\n",
    "Alternate a training epoch with the evaluation of the validation set, repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "\n",
      "\n",
      "EPOCH 1 of 300 (159.086 sec)\n",
      "-- train loss 0.36341487168626213 -- valid loss 0.33903557413853475 --\n",
      "Epoch 1, saving new best loss model, 0.33903557413853475\n",
      "\n",
      "\n",
      "EPOCH 2 of 300 (164.698 sec)\n",
      "-- train loss 0.33308682788978833 -- valid loss 0.33290436327087214 --\n",
      "Epoch 2, saving new best loss model, 0.33290436327087214\n",
      "\n",
      "\n",
      "EPOCH 3 of 300 (169.045 sec)\n",
      "-- train loss 0.3306458076949795 -- valid loss 0.3295757207811249 --\n",
      "Epoch 3, saving new best loss model, 0.3295757207811249\n",
      "\n",
      "\n",
      "EPOCH 4 of 300 (168.106 sec)\n",
      "-- train loss 0.32964072763408203 -- valid loss 0.3298109914205089 --\n",
      "\n",
      "\n",
      "EPOCH 5 of 300 (168.832 sec)\n",
      "-- train loss 0.3287846425891946 -- valid loss 0.3283388760889539 --\n",
      "Epoch 5, saving new best loss model, 0.3283388760889539\n",
      "\n",
      "\n",
      "EPOCH 6 of 300 (168.853 sec)\n",
      "-- train loss 0.3283675887937709 -- valid loss 0.3283363771364556 --\n",
      "Epoch 6, saving new best loss model, 0.3283363771364556\n",
      "\n",
      "\n",
      "EPOCH 7 of 300 (168.795 sec)\n",
      "-- train loss 0.32800453108267724 -- valid loss 0.32841680397898515 --\n",
      "\n",
      "\n",
      "EPOCH 8 of 300 (168.280 sec)\n",
      "-- train loss 0.3277230092959854 -- valid loss 0.3285965869515579 --\n",
      "\n",
      "\n",
      "EPOCH 9 of 300 (167.953 sec)\n",
      "-- train loss 0.3275162102774489 -- valid loss 0.33122935076678023 --\n",
      "\n",
      "\n",
      "EPOCH 10 of 300 (167.652 sec)\n",
      "-- train loss 0.3273358960583998 -- valid loss 0.32725844601666704 --\n",
      "Epoch 10, saving new best loss model, 0.32725844601666704\n",
      "\n",
      "\n",
      "EPOCH 11 of 300 (167.402 sec)\n",
      "-- train loss 0.3272142493098079 -- valid loss 0.328125982921316 --\n",
      "\n",
      "\n",
      "EPOCH 12 of 300 (167.942 sec)\n",
      "-- train loss 0.3270330080530674 -- valid loss 0.32688220187744 --\n",
      "Epoch 12, saving new best loss model, 0.32688220187744\n",
      "\n",
      "\n",
      "EPOCH 13 of 300 (167.673 sec)\n",
      "-- train loss 0.3269228602363828 -- valid loss 0.32692867721089663 --\n",
      "\n",
      "\n",
      "EPOCH 14 of 300 (168.221 sec)\n",
      "-- train loss 0.3268205224188612 -- valid loss 0.32727956512699957 --\n",
      "\n",
      "\n",
      "EPOCH 15 of 300 (168.835 sec)\n",
      "-- train loss 0.3266500074080643 -- valid loss 0.3274382560149483 --\n",
      "\n",
      "\n",
      "EPOCH 16 of 300 (168.116 sec)\n",
      "-- train loss 0.32663206481114987 -- valid loss 0.32663975091454406 --\n",
      "Epoch 16, saving new best loss model, 0.32663975091454406\n",
      "\n",
      "\n",
      "EPOCH 17 of 300 (168.243 sec)\n",
      "-- train loss 0.3265460582825759 -- valid loss 0.32788770150694047 --\n",
      "\n",
      "\n",
      "EPOCH 18 of 300 (167.974 sec)\n",
      "-- train loss 0.32647080684296564 -- valid loss 0.3264582564371713 --\n",
      "Epoch 18, saving new best loss model, 0.3264582564371713\n",
      "\n",
      "\n",
      "EPOCH 19 of 300 (168.131 sec)\n",
      "-- train loss 0.32626774558565647 -- valid loss 0.3268415072689886 --\n",
      "\n",
      "\n",
      "EPOCH 20 of 300 (167.875 sec)\n",
      "-- train loss 0.3263005233437718 -- valid loss 0.32698694667460754 --\n",
      "\n",
      "\n",
      "EPOCH 21 of 300 (167.616 sec)\n",
      "-- train loss 0.32613541342541896 -- valid loss 0.3280828174967203 --\n",
      "\n",
      "\n",
      "EPOCH 22 of 300 (168.562 sec)\n",
      "-- train loss 0.32622554591285313 -- valid loss 0.3262788801459792 --\n",
      "Epoch 22, saving new best loss model, 0.3262788801459792\n",
      "\n",
      "\n",
      "EPOCH 23 of 300 (167.859 sec)\n",
      "-- train loss 0.32619474818650235 -- valid loss 0.32661497611436785 --\n",
      "\n",
      "\n",
      "EPOCH 24 of 300 (167.608 sec)\n",
      "-- train loss 0.3260934418107307 -- valid loss 0.3264701840299997 --\n",
      "\n",
      "\n",
      "EPOCH 25 of 300 (167.933 sec)\n",
      "-- train loss 0.32588250535368407 -- valid loss 0.3262969442406056 --\n",
      "\n",
      "\n",
      "EPOCH 26 of 300 (168.128 sec)\n",
      "-- train loss 0.32586988506143183 -- valid loss 0.32636554418883706 --\n",
      "\n",
      "\n",
      "EPOCH 27 of 300 (168.055 sec)\n",
      "-- train loss 0.3259513063811949 -- valid loss 0.32677914341043984 --\n",
      "\n",
      "\n",
      "EPOCH 28 of 300 (167.873 sec)\n",
      "-- train loss 0.3258514289820143 -- valid loss 0.3264969285600674 --\n",
      "\n",
      "\n",
      "EPOCH 29 of 300 (167.885 sec)\n",
      "-- train loss 0.3257165125255421 -- valid loss 0.32635366898145735 --\n",
      "\n",
      "\n",
      "EPOCH 30 of 300 (167.940 sec)\n",
      "-- train loss 0.32570592697725786 -- valid loss 0.3261118057351675 --\n",
      "Epoch 30, saving new best loss model, 0.3261118057351675\n",
      "\n",
      "\n",
      "EPOCH 31 of 300 (167.289 sec)\n",
      "-- train loss 0.3256306284678852 -- valid loss 0.32612529156370934 --\n",
      "\n",
      "\n",
      "EPOCH 32 of 300 (167.431 sec)\n",
      "-- train loss 0.32569447962383347 -- valid loss 0.32613722230336684 --\n",
      "\n",
      "\n",
      "EPOCH 33 of 300 (167.690 sec)\n",
      "-- train loss 0.3255589305075453 -- valid loss 0.3262872023982291 --\n",
      "\n",
      "\n",
      "EPOCH 34 of 300 (168.183 sec)\n",
      "-- train loss 0.3255886167223873 -- valid loss 0.3269582883171413 --\n",
      "\n",
      "\n",
      "EPOCH 35 of 300 (168.111 sec)\n",
      "-- train loss 0.32555932462087517 -- valid loss 0.3261357742066709 --\n",
      "\n",
      "\n",
      "EPOCH 36 of 300 (167.450 sec)\n",
      "-- train loss 0.325459105869987 -- valid loss 0.326271796263523 --\n",
      "\n",
      "\n",
      "EPOCH 37 of 300 (167.905 sec)\n",
      "-- train loss 0.3254009413297084 -- valid loss 0.326955406006819 --\n",
      "\n",
      "\n",
      "EPOCH 38 of 300 (167.236 sec)\n",
      "-- train loss 0.3253919898568305 -- valid loss 0.32622897088157465 --\n",
      "\n",
      "\n",
      "EPOCH 39 of 300 (167.592 sec)\n",
      "-- train loss 0.32533816462422643 -- valid loss 0.3265367672310112 --\n",
      "\n",
      "\n",
      "EPOCH 40 of 300 (167.907 sec)\n",
      "-- train loss 0.32544017375282974 -- valid loss 0.3266194633075169 --\n",
      "\n",
      "\n",
      "cutting learning rate to 0.0005\n",
      "Reloading best model, from epoch 30\n",
      "\n",
      "\n",
      "EPOCH 41 of 300 (167.946 sec)\n",
      "-- train loss 0.3251560921960634 -- valid loss 0.3261302820644023 --\n",
      "\n",
      "\n",
      "EPOCH 42 of 300 (167.694 sec)\n",
      "-- train loss 0.3250632099327611 -- valid loss 0.32623144206793414 --\n",
      "\n",
      "\n",
      "EPOCH 43 of 300 (168.165 sec)\n",
      "-- train loss 0.32500376453215474 -- valid loss 0.3259053726373992 --\n",
      "Epoch 43, saving new best loss model, 0.3259053726373992\n",
      "\n",
      "\n",
      "EPOCH 44 of 300 (167.924 sec)\n",
      "-- train loss 0.3249150381259652 -- valid loss 0.32614477339738646 --\n",
      "\n",
      "\n",
      "EPOCH 45 of 300 (167.507 sec)\n",
      "-- train loss 0.324861474910775 -- valid loss 0.32609589925463894 --\n",
      "\n",
      "\n",
      "EPOCH 46 of 300 (167.770 sec)\n",
      "-- train loss 0.32486781615428145 -- valid loss 0.3260334537636419 --\n",
      "\n",
      "\n",
      "EPOCH 47 of 300 (167.489 sec)\n",
      "-- train loss 0.32472343797207903 -- valid loss 0.3260784811855103 --\n",
      "\n",
      "\n",
      "EPOCH 48 of 300 (167.862 sec)\n",
      "-- train loss 0.32464319048649254 -- valid loss 0.3259878726849645 --\n",
      "\n",
      "\n",
      "EPOCH 49 of 300 (167.742 sec)\n",
      "-- train loss 0.32462521632853497 -- valid loss 0.3262681183607682 --\n",
      "\n",
      "\n",
      "EPOCH 50 of 300 (167.839 sec)\n",
      "-- train loss 0.32454607523817874 -- valid loss 0.32632565905588756 --\n",
      "\n",
      "\n",
      "EPOCH 51 of 300 (168.368 sec)\n",
      "-- train loss 0.32448115535560085 -- valid loss 0.32606675147269826 --\n",
      "\n",
      "\n",
      "EPOCH 52 of 300 (167.712 sec)\n",
      "-- train loss 0.32439392648413456 -- valid loss 0.3261330157333279 --\n",
      "\n",
      "\n",
      "EPOCH 53 of 300 (168.397 sec)\n",
      "-- train loss 0.32437135563771613 -- valid loss 0.3262091325306744 --\n",
      "\n",
      "\n",
      "cutting learning rate to 0.00025\n",
      "Reloading best model, from epoch 43\n",
      "\n",
      "\n",
      "EPOCH 54 of 300 (167.282 sec)\n",
      "-- train loss 0.3246652167050624 -- valid loss 0.32595943775236236 --\n",
      "\n",
      "\n",
      "EPOCH 55 of 300 (167.124 sec)\n",
      "-- train loss 0.32457156524126113 -- valid loss 0.3259902292897242 --\n",
      "\n",
      "\n",
      "EPOCH 56 of 300 (167.669 sec)\n",
      "-- train loss 0.32447716433858664 -- valid loss 0.32594979938513 --\n",
      "\n",
      "\n",
      "EPOCH 57 of 300 (167.599 sec)\n",
      "-- train loss 0.324419111812831 -- valid loss 0.3259827144767927 --\n",
      "\n",
      "\n",
      "EPOCH 58 of 300 (167.806 sec)\n",
      "-- train loss 0.32434240076291204 -- valid loss 0.3261824731500993 --\n",
      "\n",
      "\n",
      "EPOCH 59 of 300 (167.542 sec)\n",
      "-- train loss 0.3242767898629663 -- valid loss 0.32615239834933546 --\n",
      "\n",
      "\n",
      "EPOCH 60 of 300 (167.617 sec)\n",
      "-- train loss 0.32420264744067906 -- valid loss 0.3260602499387279 --\n",
      "\n",
      "\n",
      "EPOCH 61 of 300 (168.242 sec)\n",
      "-- train loss 0.3241494627341692 -- valid loss 0.3260821851884356 --\n",
      "\n",
      "\n",
      "EPOCH 62 of 300 (167.884 sec)\n",
      "-- train loss 0.3240645512490825 -- valid loss 0.3260772217134511 --\n",
      "\n",
      "\n",
      "EPOCH 63 of 300 (167.515 sec)\n",
      "-- train loss 0.3239996035787169 -- valid loss 0.3261592406663835 --\n",
      "\n",
      "\n",
      "cutting learning rate to 0.000125\n",
      "Reloading best model, from epoch 43\n",
      "\n",
      "\n",
      "EPOCH 64 of 300 (167.609 sec)\n",
      "-- train loss 0.32455307069382444 -- valid loss 0.3258857586369011 --\n",
      "Epoch 64, saving new best loss model, 0.3258857586369011\n",
      "\n",
      "\n",
      "EPOCH 65 of 300 (167.764 sec)\n",
      "-- train loss 0.3244717898798603 -- valid loss 0.325888622991787 --\n",
      "\n",
      "\n",
      "EPOCH 66 of 300 (167.343 sec)\n",
      "-- train loss 0.32440256260239514 -- valid loss 0.3259586299428288 --\n",
      "\n",
      "\n",
      "EPOCH 67 of 300 (167.297 sec)\n",
      "-- train loss 0.32434453540221814 -- valid loss 0.32590657472610474 --\n",
      "\n",
      "\n",
      "EPOCH 68 of 300 (167.262 sec)\n",
      "-- train loss 0.3242832071791391 -- valid loss 0.326003219585241 --\n",
      "\n",
      "\n",
      "EPOCH 69 of 300 (167.448 sec)\n",
      "-- train loss 0.3242374569049721 -- valid loss 0.3259694128303054 --\n",
      "\n",
      "\n",
      "EPOCH 70 of 300 (167.431 sec)\n",
      "-- train loss 0.32418479134084843 -- valid loss 0.3260560117152907 --\n",
      "\n",
      "\n",
      "EPOCH 71 of 300 (167.911 sec)\n",
      "-- train loss 0.32413843619465316 -- valid loss 0.3259629579434484 --\n",
      "\n",
      "\n",
      "EPOCH 72 of 300 (167.479 sec)\n",
      "-- train loss 0.32408578252587705 -- valid loss 0.32601674909917466 --\n",
      "\n",
      "\n",
      "EPOCH 73 of 300 (167.665 sec)\n",
      "-- train loss 0.3240212330298874 -- valid loss 0.3260773648016201 --\n",
      "\n",
      "\n",
      "EPOCH 74 of 300 (167.374 sec)\n",
      "-- train loss 0.32396920584941624 -- valid loss 0.3260734460738875 --\n",
      "\n",
      "\n",
      "cutting learning rate to 6.25e-05\n",
      "Reloading best model, from epoch 64\n",
      "\n",
      "\n",
      "EPOCH 75 of 300 (167.512 sec)\n",
      "-- train loss 0.3244094654533996 -- valid loss 0.3258966551804394 --\n",
      "\n",
      "\n",
      "EPOCH 76 of 300 (167.200 sec)\n",
      "-- train loss 0.3243580643775125 -- valid loss 0.32592776436243 --\n",
      "\n",
      "\n",
      "EPOCH 77 of 300 (167.491 sec)\n",
      "-- train loss 0.3243168245825133 -- valid loss 0.3259428108330839 --\n",
      "\n",
      "\n",
      "EPOCH 78 of 300 (167.975 sec)\n",
      "-- train loss 0.324284962926044 -- valid loss 0.32591850305936354 --\n",
      "\n",
      "\n",
      "EPOCH 79 of 300 (167.179 sec)\n",
      "-- train loss 0.3242522481301312 -- valid loss 0.32592413218125055 --\n",
      "\n",
      "\n",
      "EPOCH 80 of 300 (167.759 sec)\n",
      "-- train loss 0.3242142373464138 -- valid loss 0.3259233700932923 --\n",
      "\n",
      "\n",
      "EPOCH 81 of 300 (167.296 sec)\n",
      "-- train loss 0.3241903678605996 -- valid loss 0.3260150222304445 --\n",
      "\n",
      "\n",
      "EPOCH 82 of 300 (167.378 sec)\n",
      "-- train loss 0.32414689455421186 -- valid loss 0.32594182365429325 --\n",
      "\n",
      "\n",
      "EPOCH 83 of 300 (167.855 sec)\n",
      "-- train loss 0.32412462189090097 -- valid loss 0.325964800874639 --\n",
      "\n",
      "\n",
      "EPOCH 84 of 300 (167.441 sec)\n",
      "-- train loss 0.3240900865951833 -- valid loss 0.3260022736854435 --\n",
      "\n",
      "\n",
      "cutting learning rate to 3.125e-05\n",
      "Reloading best model, from epoch 64\n",
      "\n",
      "\n",
      "EPOCH 85 of 300 (167.242 sec)\n",
      "-- train loss 0.3243808398430951 -- valid loss 0.3258694650963967 --\n",
      "Epoch 85, saving new best loss model, 0.3258694650963967\n",
      "\n",
      "\n",
      "EPOCH 86 of 300 (167.526 sec)\n",
      "-- train loss 0.32434797331754744 -- valid loss 0.32590402801584756 --\n",
      "\n",
      "\n",
      "EPOCH 87 of 300 (167.392 sec)\n",
      "-- train loss 0.32432287026500495 -- valid loss 0.32588242855131255 --\n",
      "\n",
      "\n",
      "EPOCH 88 of 300 (167.590 sec)\n",
      "-- train loss 0.32429954873262046 -- valid loss 0.3259025627041455 --\n",
      "\n",
      "\n",
      "EPOCH 89 of 300 (167.972 sec)\n",
      "-- train loss 0.3242742746684684 -- valid loss 0.32590370852014294 --\n",
      "\n",
      "\n",
      "EPOCH 90 of 300 (167.594 sec)\n",
      "-- train loss 0.324259384922971 -- valid loss 0.32590813518310924 --\n",
      "\n",
      "\n",
      "EPOCH 91 of 300 (167.429 sec)\n",
      "-- train loss 0.3242380651025813 -- valid loss 0.32589287657915433 --\n",
      "\n",
      "\n",
      "EPOCH 92 of 300 (167.980 sec)\n",
      "-- train loss 0.3242205395143431 -- valid loss 0.3259093072843848 --\n",
      "\n",
      "\n",
      "EPOCH 93 of 300 (168.191 sec)\n",
      "-- train loss 0.32420568580663256 -- valid loss 0.3259638373896202 --\n",
      "\n",
      "\n",
      "EPOCH 94 of 300 (167.883 sec)\n",
      "-- train loss 0.3241845737071508 -- valid loss 0.3259197184758157 --\n",
      "\n",
      "\n",
      "EPOCH 95 of 300 (167.855 sec)\n",
      "-- train loss 0.3241680385984576 -- valid loss 0.3259212628284596 --\n",
      "\n",
      "\n",
      "cutting learning rate to 1.5625e-05\n",
      "Reloading best model, from epoch 85\n",
      "\n",
      "\n",
      "EPOCH 96 of 300 (167.489 sec)\n",
      "-- train loss 0.32432887373819885 -- valid loss 0.3258779872648464 --\n",
      "\n",
      "\n",
      "EPOCH 97 of 300 (167.682 sec)\n",
      "-- train loss 0.32431468876006775 -- valid loss 0.3258858184266535 --\n",
      "\n",
      "\n",
      "EPOCH 98 of 300 (167.883 sec)\n",
      "-- train loss 0.3243023007148837 -- valid loss 0.32588577973916666 --\n",
      "\n",
      "\n",
      "EPOCH 99 of 300 (167.003 sec)\n",
      "-- train loss 0.324290581655093 -- valid loss 0.3258845174904936 --\n",
      "\n",
      "\n",
      "EPOCH 100 of 300 (167.499 sec)\n",
      "-- train loss 0.3242793431417625 -- valid loss 0.3258825921864243 --\n",
      "\n",
      "\n",
      "EPOCH 101 of 300 (167.060 sec)\n",
      "-- train loss 0.32426688241344664 -- valid loss 0.32588369191063116 --\n",
      "\n",
      "\n",
      "EPOCH 102 of 300 (167.581 sec)\n",
      "-- train loss 0.3242561383564585 -- valid loss 0.325908947435225 --\n",
      "\n",
      "\n",
      "EPOCH 103 of 300 (167.540 sec)\n",
      "-- train loss 0.32424548840701833 -- valid loss 0.3258916071112852 --\n",
      "\n",
      "\n",
      "EPOCH 104 of 300 (167.118 sec)\n",
      "-- train loss 0.32423647608240275 -- valid loss 0.3259080728018506 --\n",
      "\n",
      "\n",
      "EPOCH 105 of 300 (167.444 sec)\n",
      "-- train loss 0.3242248064586533 -- valid loss 0.3258985777078948 --\n",
      "\n",
      "\n",
      "cutting learning rate to 7.8125e-06\n",
      "Reloading best model, from epoch 85\n",
      "\n",
      "\n",
      "EPOCH 106 of 300 (167.390 sec)\n",
      "-- train loss 0.3243208574251044 -- valid loss 0.32587665708168695 --\n",
      "\n",
      "\n",
      "EPOCH 107 of 300 (167.175 sec)\n",
      "-- train loss 0.3243117688039853 -- valid loss 0.3258728745931424 --\n",
      "\n",
      "\n",
      "EPOCH 108 of 300 (167.429 sec)\n",
      "-- train loss 0.3243052626884035 -- valid loss 0.3258771440997627 --\n",
      "\n",
      "\n",
      "EPOCH 109 of 300 (167.140 sec)\n",
      "-- train loss 0.3242966806108348 -- valid loss 0.3258892642044873 --\n",
      "\n",
      "\n",
      "EPOCH 110 of 300 (168.194 sec)\n",
      "-- train loss 0.3242931658234207 -- valid loss 0.32589112620176 --\n",
      "\n",
      "\n",
      "EPOCH 111 of 300 (167.749 sec)\n",
      "-- train loss 0.3242858192951382 -- valid loss 0.3258885406189083 --\n",
      "\n",
      "\n",
      "EPOCH 112 of 300 (167.731 sec)\n",
      "-- train loss 0.3242777321215863 -- valid loss 0.3258902571216133 --\n",
      "\n",
      "\n",
      "EPOCH 113 of 300 (167.627 sec)\n",
      "-- train loss 0.32427391723246024 -- valid loss 0.32588491232498834 --\n",
      "\n",
      "\n",
      "EPOCH 114 of 300 (167.194 sec)\n",
      "-- train loss 0.32426948397712135 -- valid loss 0.3258887353520956 --\n",
      "\n",
      "\n",
      "EPOCH 115 of 300 (167.309 sec)\n",
      "-- train loss 0.3242620752540781 -- valid loss 0.3258881178331671 --\n",
      "\n",
      "\n",
      "cutting learning rate to 3.90625e-06\n",
      "Reloading best model, from epoch 85\n",
      "\n",
      "\n",
      "EPOCH 116 of 300 (167.353 sec)\n",
      "-- train loss 0.3243199720211295 -- valid loss 0.32587381456949693 --\n",
      "\n",
      "\n",
      "EPOCH 117 of 300 (166.928 sec)\n",
      "-- train loss 0.3243127236934179 -- valid loss 0.325875455178089 --\n",
      "\n",
      "\n",
      "EPOCH 118 of 300 (167.390 sec)\n",
      "-- train loss 0.3243073034759755 -- valid loss 0.3258728749633576 --\n",
      "\n",
      "\n",
      "EPOCH 119 of 300 (167.310 sec)\n",
      "-- train loss 0.32430277707239075 -- valid loss 0.3258808568027449 --\n",
      "\n",
      "\n",
      "EPOCH 120 of 300 (167.710 sec)\n",
      "-- train loss 0.32429969592155816 -- valid loss 0.3258800628762808 --\n",
      "\n",
      "\n",
      "EPOCH 121 of 300 (167.424 sec)\n",
      "-- train loss 0.32429658746258894 -- valid loss 0.32587847132120074 --\n",
      "\n",
      "\n",
      "EPOCH 122 of 300 (167.817 sec)\n",
      "-- train loss 0.32429135600384723 -- valid loss 0.3258796141754766 --\n",
      "\n",
      "\n",
      "EPOCH 123 of 300 (167.441 sec)\n",
      "-- train loss 0.32428851180066365 -- valid loss 0.32588011044893206 --\n",
      "\n",
      "\n",
      "EPOCH 124 of 300 (167.107 sec)\n",
      "-- train loss 0.3242855066905206 -- valid loss 0.3258823267421367 --\n",
      "\n",
      "\n",
      "EPOCH 125 of 300 (167.878 sec)\n",
      "-- train loss 0.32428245978677733 -- valid loss 0.32588074314668314 --\n",
      "\n",
      "\n",
      "cutting learning rate to 1.953125e-06\n",
      "Reloading best model, from epoch 85\n",
      "\n",
      "\n",
      "EPOCH 126 of 300 (167.207 sec)\n",
      "-- train loss 0.32431739354466166 -- valid loss 0.3258711384690326 --\n",
      "Breaking on patience, epoch 126.\n",
      "Reloading best model, from epoch 85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For saving and restoring the best val loss model.\n",
    "best_model_file = tempfile.NamedTemporaryFile(mode='w+b', delete=False)\n",
    "best_epoch = -1\n",
    "min_val_loss = 1e15\n",
    "\n",
    "\n",
    "\n",
    "# To ensure we don't go on too long\n",
    "patienceLimit, patience = training_args.patienceLimit, 0\n",
    "patienceToLRcut = training_args.patienceToLRcut\n",
    "\n",
    "\n",
    "# Report dices every some number epochs.\n",
    "howOftenToReport = training_args.howOftenToReport \n",
    "\n",
    "# For updating the learning rate during training.\n",
    "cur_learning_rate = training_args.learning_rate\n",
    "num_epochs = training_args.num_epochs\n",
    "\n",
    "\n",
    "print('STARTING TRAINING')\n",
    "\n",
    "for i in range(1, num_epochs+1):\n",
    "    if patience == patienceToLRcut or (patience > patienceToLRcut \n",
    "                                       and patience % patienceToLRcut == 0): \n",
    "        cur_learning_rate /= 2 \n",
    "        print('\\n\\ncutting learning rate to {}'.format(cur_learning_rate))\n",
    "        print('Reloading best model, from epoch {}'.format(best_epoch))\n",
    "        net_seg.load_state_dict(torch.load(best_model_file.name))\n",
    "        \n",
    "    # Run the training epoch and validation test, and report.\n",
    "    start = tic()\n",
    "    train_loss, train_output_seg, train_input_img, train_label = \\\n",
    "        run_training(net_seg, \n",
    "                     effective_batchsize = training_args.effective_batchsize,\n",
    "                     cur_learning_rate = cur_learning_rate,\n",
    "                     cur_weight_decay = training_args.weight_decay)\n",
    "\n",
    "    valid_loss, valid_output_seg, valid_input_img, val_label = \\\n",
    "        run_validation(net_seg, \n",
    "                       phase = 'val')\n",
    "\n",
    "    print('\\n\\nEPOCH {} of {} ({:.3f} sec)'.format(i, num_epochs, toc()-start))\n",
    "    print('-- train loss {} -- valid loss {} --'.format(train_loss, valid_loss))\n",
    "    \n",
    "    \n",
    "    # Initially, whether to visualize this iteration.\n",
    "    visThisIter = (i % howOftenToReport) == 1\n",
    "\n",
    "\n",
    "    ########### Check for best so far model \n",
    "\n",
    "    # Now save if this is the best model so far\n",
    "    if valid_loss < min_val_loss:\n",
    "        min_val_loss = valid_loss\n",
    "#             if (i > 20):\n",
    "#                 visThisIter = True # Only sometimes viz best so far. kind of slow.\n",
    "        patience = 0\n",
    "        best_epoch = i\n",
    "        print('Epoch {}, saving new best loss model, {}'.format(i, valid_loss))\n",
    "        torch.save(net_seg.state_dict(), best_model_file.name) \n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= patienceLimit:\n",
    "            print('Breaking on patience, epoch {}.'.format(i))\n",
    "            break\n",
    "\n",
    "\n",
    "    ########### Potentially report results this iter.\n",
    "\n",
    "#     if visThisIter:\n",
    "#         report_validation_sets(net_seg=net_seg, datadict=datadict, args=args)\n",
    "\n",
    "\n",
    "\n",
    "# After all the training, now reload the best model.\n",
    "print('Reloading best model, from epoch {}'.format(best_epoch))\n",
    "net_seg.load_state_dict(torch.load(best_model_file.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_seg.load_state_dict(torch.load(best_model_file.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_seg.eval()\n",
    "\n",
    "net_outputs = torch.tensor([])\n",
    "target_outputs = torch.tensor([]).type(torch.long)\n",
    "test_frames = torch.tensor([])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch_num, (camusized_frames, camusized_traces) in \\\n",
    "        enumerate(map(Camusize(im_size=training_args.image_size), dataloaders['test'])):\n",
    "        \n",
    "        \n",
    "        # Add to the test_frames\n",
    "        test_frames = torch.cat((test_frames, camusized_frames), 0)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            camusized_frames = camusized_frames.cuda()\n",
    "        \n",
    "        # Push through the network\n",
    "        inputs = Variable(camusized_frames)\n",
    "        \n",
    "        net_outputs = torch.cat((net_outputs,\n",
    "                                 net_seg(inputs).detach().cpu()),\n",
    "                                0)\n",
    "        \n",
    "        # Add to target answers\n",
    "        target_outputs = torch.cat((target_outputs, camusized_traces), 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2552, 2, 256, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dice business just here.\n",
    "def getDices(autoseg, labels, whichLabels=['Background', 'Left Ventricle']):\n",
    "    \n",
    "    # Similar to code in visOverlay, where we want to find the choice made by\n",
    "    # the autoseg\n",
    "    mchanLabelKey = (autoseg > 0).astype(np.uint8).squeeze() # should be (N, H, W)\n",
    "    \n",
    "    labels = labels.squeeze() # should be (N, H, W) \n",
    "    \n",
    "    retDice = np.zeros((autoseg.shape[0], len(whichLabels)))\n",
    "    \n",
    "    for case in range(autoseg.shape[0]):\n",
    "        for i, key in enumerate(whichLabels):\n",
    "            seg = (mchanLabelKey[case]==nameLabMap[key]).astype(np.uint8)\n",
    "            lab = (labels[case]==nameLabMap[key]).astype(np.uint8)\n",
    "            \n",
    "#             print(seg.max(), lab.max()) debug\n",
    "            # Dice is intersection over average\n",
    "#             print('lab {}, seg {}, intersect {}'.format(lab.sum(), seg.sum(), (seg*lab).sum()))\n",
    "            retDice[case][i] = (2.0*((seg*lab).sum()))/(seg.sum() + lab.sum())\n",
    "    \n",
    "    return retDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = getDices((torch.argmax(net_outputs, 1)==nameLabMap['Left Ventricle']).numpy(), target_outputs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.922743060622721, 0.04441620803445517)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dices[:,1].mean(), dices[:,1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053877eae99f495eada9a3a1d8acc02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(dices[:,1], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
